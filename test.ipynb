{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35fb1d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pc\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Transformers version: 4.57.1\n",
      "Datasets version: 4.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "import datasets\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Datasets version: {datasets.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70866816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pc\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = TFAutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    use_safetensors=False\n",
    ")\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f460c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized inputs:\n",
      "Input IDs shape: (1, 11)\n",
      "Attention mask shape: (1, 11)\n",
      "\n",
      "Input Ids: [[ 101 2023 2003 1037 3231 6251 2005 1996 2944 1012  102]]\n",
      "\n",
      "Model output shape: (1, 11, 768)\n",
      "Model inference successful!\n"
     ]
    }
   ],
   "source": [
    "#Test with simple input\n",
    "text = \"This is a test sentence for the model.\" #Test tokenizer and model\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"tf\", padding=True, truncation=True)#Tokenize text\n",
    "\n",
    "print(\"Tokenized inputs:\")\n",
    "print(f\"Input IDs shape: {inputs['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {inputs['attention_mask'].shape}\")\n",
    "print(f\"\\nInput Ids: {inputs['input_ids']}\")\n",
    "\n",
    "# Get model output\n",
    "outputs = model(inputs)\n",
    "print(f\"\\nModel output shape: {outputs.last_hidden_state.shape}\")\n",
    "print(\"Model inference successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "Dataset splits: ['train', 'test', 'unsupervised']\n",
      "Training examples: 25000\n",
      "Test examples: 25000\n",
      "\n",
      "--- Sample Example ---\n",
      "Text: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ev...\n",
      "Label: 0 (0=negative, 1=positive)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load IMDB dataset (movie reviews)\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "print(f\"\\nDataset splits: {list(dataset.keys())}\")\n",
    "print(f\"Training examples: {len(dataset['train'])}\")\n",
    "print(f\"Test examples: {len(dataset['test'])}\")\n",
    "\n",
    "# Show a sample\n",
    "print(f\"\\n--- Sample Example ---\")\n",
    "print(f\"Text: {dataset['train'][0]['text'][:200]}...\")\n",
    "print(f\"Label: {dataset['train'][0]['label']} (0=negative, 1=positive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be09c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset... (this may take a minute)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:27<00:00, 894.42 examples/s] \n",
      "Map: 100%|██████████| 25000/25000 [00:30<00:00, 824.28 examples/s] \n",
      "Map: 100%|██████████| 50000/50000 [00:54<00:00, 924.20 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization complete!\n",
      "Features: ['text', 'label', 'input_ids', 'attention_mask']\n",
      "\n",
      "Tokenized example shape: 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Apply tokenization to the entire dataset\n",
    "print(\"Tokenizing dataset... (this may take a minute)\")\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "print(\"\\nTokenization complete!\")\n",
    "print(f\"Features: {tokenized_dataset['train'].column_names}\")\n",
    "\n",
    "# Check a tokenized example\n",
    "print(f\"\\nTokenized example shape: {len(tokenized_dataset['train'][0]['input_ids'])} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c907c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\datasets\\arrow_dataset.py:405: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets converted to Tensorflow format!\n",
      "Training batches: ~62\n",
      "Test batches: ~12\n"
     ]
    }
   ],
   "source": [
    "#6Convert to TensorFlow dataset\n",
    "\n",
    "small_train_dataset = tokenized_dataset['train'].shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = tokenized_dataset['test'].shuffle(seed=42).select(range(200))\n",
    "\n",
    "#Convert to TF dataset\n",
    "train_dataset = small_train_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask'],\n",
    "    label_cols=['label'],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=None\n",
    ")\n",
    "\n",
    "test_dataset = small_test_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask'],\n",
    "    label_cols=['label'],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=None\n",
    ")\n",
    "\n",
    "print(\"Datasets converted to Tensorflow format!\")\n",
    "print(f\"Training batches: ~{len(small_train_dataset) // 16}\")\n",
    "print(f\"Test batches: ~{len(small_test_dataset) // 16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7734af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_152']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification model loaded successfully!\n",
      "Model has 2 output labels\n"
     ]
    }
   ],
   "source": [
    "#7Load Model for Classification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "#Load pre-trained model with classification head\n",
    "model_for_classification = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    use_safetensors=False\n",
    ")\n",
    "print(\"Classification model loaded successfully!\")\n",
    "print(f\"Model has {model_for_classification.num_labels} output labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2410a0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled and ready for training!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#8 Compile the model\n",
    "model_for_classification.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled and ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be1bfc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\pc\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\pc\\anaconda3\\envs\\tf-env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "63/63 [==============================] - 962s 14s/step - loss: 0.5502 - accuracy: 0.7220 - val_loss: 0.4804 - val_accuracy: 0.7600\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 764s 12s/step - loss: 0.3126 - accuracy: 0.8820 - val_loss: 0.5017 - val_accuracy: 0.7850\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 771s 12s/step - loss: 0.1785 - accuracy: 0.9390 - val_loss: 0.5495 - val_accuracy: 0.7800\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#9 Train model\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "history = model_for_classification.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60e04563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.5495 - accuracy: 0.7800\n",
      "\n",
      "Test Loss: 0.5495\n",
      "Test Accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "#10. Evaluate Model\n",
    "print(\"Evaluating model...\")\n",
    "results = model_for_classification.evaluate(test_dataset)\n",
    "\n",
    "print(f\"\\nTest Loss: {results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a203900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: This movie was absolutely fantastic! I loved every minute of...\n",
      "Sentiment: positive (confidence: 97.98%)\n",
      "\n",
      "Review: Terrible film. Complete waste of time and money....\n",
      "Sentiment: Negative (confidence: 98.32%)\n",
      "\n",
      "Review: It was okay, nothing special but not bad either....\n",
      "Sentiment: Negative (confidence: 83.54%)\n"
     ]
    }
   ],
   "source": [
    "#11: Make Predictions on New Text\n",
    "\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely fantastic! I loved every minute of it.\",\n",
    "    \"Terrible film. Complete waste of time and money.\",\n",
    "    \"It was okay, nothing special but not bad either.\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    #Tokenize\n",
    "    inputs = tokenizer(review, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
    "    #Predict\n",
    "    outputs = model_for_classification(inputs)\n",
    "    predictions = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "    predicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\n",
    "    confidence = predictions.numpy()[0][predicted_class]\n",
    "\n",
    "    sentiment = \"positive\" if predicted_class == 1 else \"Negative\"\n",
    "\n",
    "    print(f\"\\nReview: {review[:60]}...\")\n",
    "    print(f\"Sentiment: {sentiment} (confidence: {confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e20ab9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./my_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "#12 Save model and tokenizer\n",
    "\n",
    "save_path = \"./my_sentiment_model\"\n",
    "\n",
    "model_for_classification.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa55c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./my_sentiment_model were not used when initializing TFDistilBertForSequenceClassification: ['dropout_152']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ./my_sentiment_model and are newly initialized: ['dropout_172']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disk successfully!\n",
      "Prediction: Positive\n"
     ]
    }
   ],
   "source": [
    "#13 Load Saved Model Later\n",
    "\n",
    "loaded_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    save_path,\n",
    "    use_safetensors=False\n",
    ")\n",
    "\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "\n",
    "print(\"Model loaded from disk successfully!\")\n",
    "\n",
    "#Test loaded model\n",
    "test_text = \"This is amazing product!\"\n",
    "inputs = loaded_tokenizer(test_text, return_tensors=\"tf\") \n",
    "outputs = loaded_model(inputs)\n",
    "prediction = tf.argmax(outputs.logits, axis=-1).numpy()[0]\n",
    "\n",
    "print(f\"Prediction: {'Positive' if prediction == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# kernel = torch.tensor([\n",
    "#     [0, -1, 0],\n",
    "#     [-1, 5, -1],\n",
    "#     [0, -1, 0],\n",
    "# ], dtype=torch.float32)\n",
    "\n",
    "# bias = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "# image = torch.tensor(\n",
    "#     [[1,2,3,4],\n",
    "#     [5,6,7,8],\n",
    "#     [9,10,11,12],\n",
    "#     [13,14,15,16]], dtype=torch.float32\n",
    "# )\n",
    "\n",
    "# def Output_shape(image, kernel, padding, stride):\n",
    "#     h, w = image.shape[-2], image.shape[-1]\n",
    "#     k_h, k_w = kernel.shape[-2], kernel.shape[-1]\n",
    "\n",
    "#     h_out = (h-k_h * padding) // stride[0] +1\n",
    "#     w_out = (w-k_w * pading) // stride[1] + 1\n",
    "#     return h_out, w_out\n",
    "# Output_shape(image, kernel, padding=0, stride=(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
